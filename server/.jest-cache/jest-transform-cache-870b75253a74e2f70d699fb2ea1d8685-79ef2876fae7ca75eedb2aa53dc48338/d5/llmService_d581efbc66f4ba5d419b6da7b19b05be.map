{"file":"/Users/michaelmcisaac/GitHub/teaching-engine2.0/server/src/services/llmService.ts","mappings":"AAAA,OAAO,MAAM,MAAM,QAAQ,CAAC;AAC5B,OAAO,MAAM,MAAM,WAAW,CAAC;AAE/B,IAAI,MAAM,GAAkB,IAAI,CAAC;AACjC,IAAI,OAAO,CAAC,GAAG,CAAC,cAAc,EAAE,CAAC;IAC/B,MAAM,GAAG,IAAI,MAAM,CAAC,EAAE,MAAM,EAAE,OAAO,CAAC,GAAG,CAAC,cAAc,EAAE,CAAC,CAAC;AAC9D,CAAC;AAED,OAAO,EAAE,MAAM,EAAE,CAAC;AAElB,MAAM,CAAC,KAAK,UAAU,eAAe,CAAC,MAAc,EAAE,aAAsB;IAC1E,IAAI,CAAC,MAAM,EAAE,CAAC;QACZ,MAAM,CAAC,IAAI,CAAC,8DAA8D,CAAC,CAAC;QAC5E,OAAO,+FAA+F,CAAC;IACzG,CAAC;IAED,IAAI,CAAC;QACH,MAAM,QAAQ,GAAyD,EAAE,CAAC;QAE1E,IAAI,aAAa,EAAE,CAAC;YAClB,QAAQ,CAAC,IAAI,CAAC;gBACZ,IAAI,EAAE,QAAQ;gBACd,OAAO,EAAE,aAAa;aACvB,CAAC,CAAC;QACL,CAAC;QAED,QAAQ,CAAC,IAAI,CAAC;YACZ,IAAI,EAAE,MAAM;YACZ,OAAO,EAAE,MAAM;SAChB,CAAC,CAAC;QAEH,MAAM,IAAI,GAAG,MAAM,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YAChD,KAAK,EAAE,eAAe;YACtB,QAAQ;YACR,WAAW,EAAE,GAAG;YAChB,UAAU,EAAE,IAAI;SACjB,CAAC,CAAC;QAEH,IAAI,IAAI,EAAE,KAAK,EAAE,YAAY,EAAE,CAAC;YAC9B,MAAM,CAAC,IAAI,CAAC,EAAE,MAAM,EAAE,IAAI,CAAC,KAAK,CAAC,YAAY,EAAE,EAAE,wCAAwC,CAAC,CAAC;QAC7F,CAAC;QAED,OAAO,IAAI,EAAE,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,EAAE,IAAI,EAAE,IAAI,sBAAsB,CAAC;IAChF,CAAC;IAAC,OAAO,GAAG,EAAE,CAAC;QACb,MAAM,CAAC,KAAK,CAAC,EAAE,GAAG,EAAE,EAAE,+BAA+B,CAAC,CAAC;QACvD,OAAO,qDAAqD,CAAC;IAC/D,CAAC;AACH,CAAC;AAED,MAAM,CAAC,KAAK,UAAU,wBAAwB,CAC5C,MAAc,EACd,aAAsB;IAEtB,MAAM,sBAAsB,GAAG,GAAG,aAAa,IAAI,EAAE;;;;;;uBAMhC,CAAC;IAEtB,MAAM,OAAO,GAAG,MAAM,eAAe,CAAC,MAAM,EAAE,sBAAsB,CAAC,CAAC;IAEtE,+BAA+B;IAC/B,MAAM,WAAW,GAAG,OAAO,CAAC,KAAK,CAAC,qCAAqC,CAAC,CAAC;IACzE,MAAM,YAAY,GAAG,OAAO,CAAC,KAAK,CAAC,yBAAyB,CAAC,CAAC;IAE9D,OAAO;QACL,MAAM,EAAE,WAAW,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,IAAI,OAAO;QAC3C,OAAO,EAAE,YAAY,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,IAAI,OAAO;KAC9C,CAAC;AACJ,CAAC","names":[],"sources":["/Users/michaelmcisaac/GitHub/teaching-engine2.0/server/src/services/llmService.ts"],"sourcesContent":["import OpenAI from 'openai';\nimport logger from '../logger';\n\nlet openai: OpenAI | null = null;\nif (process.env.OPENAI_API_KEY) {\n  openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });\n}\n\nexport { openai };\n\nexport async function generateContent(prompt: string, systemMessage?: string): Promise<string> {\n  if (!openai) {\n    logger.warn('OpenAI API key not configured, returning placeholder content');\n    return 'AI content generation is not available. Please configure OPENAI_API_KEY environment variable.';\n  }\n\n  try {\n    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [];\n\n    if (systemMessage) {\n      messages.push({\n        role: 'system',\n        content: systemMessage,\n      });\n    }\n\n    messages.push({\n      role: 'user',\n      content: prompt,\n    });\n\n    const chat = await openai.chat.completions.create({\n      model: 'gpt-3.5-turbo',\n      messages,\n      temperature: 0.7,\n      max_tokens: 1000,\n    });\n\n    if (chat?.usage?.total_tokens) {\n      logger.info({ tokens: chat.usage.total_tokens }, 'LLM tokens used for content generation');\n    }\n\n    return chat?.choices?.[0]?.message?.content?.trim() || 'No content generated';\n  } catch (err) {\n    logger.error({ err }, 'LLM content generation failed');\n    return 'Failed to generate content. Please try again later.';\n  }\n}\n\nexport async function generateBilingualContent(\n  prompt: string,\n  systemMessage?: string,\n): Promise<{ french: string; english: string }> {\n  const bilingualSystemMessage = `${systemMessage || ''}\\n\\nPlease respond with content in both French and English. Format your response as:\n\nFRENCH:\n[French content here]\n\nENGLISH:\n[English content here]`;\n\n  const content = await generateContent(prompt, bilingualSystemMessage);\n\n  // Parse the bilingual response\n  const frenchMatch = content.match(/FRENCH:\\s*([\\s\\S]*?)(?=ENGLISH:|$)/i);\n  const englishMatch = content.match(/ENGLISH:\\s*([\\s\\S]*?)$/i);\n\n  return {\n    french: frenchMatch?.[1]?.trim() || content,\n    english: englishMatch?.[1]?.trim() || content,\n  };\n}\n"],"version":3}